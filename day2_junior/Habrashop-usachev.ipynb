{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip, json \n",
    "corpus=[] \n",
    "for line in gzip.open(\"habra_corpus.json.gz\"): \n",
    "    corpus.append(json.loads(line.decode('utf8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Не так давно в рамках тестирования продуктовых линеек EMC мне довелось поработать с их решением EMC Avamar Virtual Edition. Этим опытом я и хочу поделиться с вами в этой публикации.\n",
      "\n",
      "\n",
      "\n",
      "История проблемы\r\n",
      "Пообщавшись с коллегами с различных компаний, я сделал вывод, что многие пренебрегают резервным копированием рабочих станций сотрудников компании, ограничиваясь лишь копированием продакшн-приложений.\n",
      "\r\n",
      "С одной стороны, это понятно — даже для «боевых» сервисов еще не так много устоявшихся практик, «пошедших в массы». Поэтому обеспечение хороших показателей RTO и RPO для критичных сервисов является одной из основных головных болей ИТ-отделов как крупных, так и средних компаний. Уделять же время такой мелочи, как резервное копирование пользовательских машин — это непозволительная роскошь.\n",
      "\r\n",
      "Однако, на практике это означает, что поломка рабочей станции приводит либо к переносу жестких дисков из старого устройства в новое (с последующими сложностями по инвентаризации и учету), либо к \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print corpus[2]['text'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = nltk.snowball.RussianStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_tokenizer = nltk.tokenize.RegexpTokenizer(r'[А-Яа-яA-Za-z0-9]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_tokenizer.tokenize (u'я умный и умелый')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer2 = nltk.tokenize.WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a= tokenizer2.tokenize (u'я умный и умелый')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'\\u044f', u'\\u0443\\u043c\\u043d\\u044b\\u0439', u'\\u0438', u'\\u0443\\u043c\\u0435\\u043b\\u044b\\u0439']\n"
     ]
    }
   ],
   "source": [
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "я\n",
      "умный\n",
      "и\n",
      "умелый\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "я\n",
      "умн\n",
      "и\n",
      "умел\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    i = stemmer.stem(i)\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Не \n"
     ]
    }
   ],
   "source": [
    "print corpus[2]['text'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "уж\n",
      "писа\n",
      "про\n",
      "классификац\n",
      "и\n",
      "два\n",
      "основн\n",
      "пут\n",
      "создан\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenized_corpus=[]\n",
    "for i in corpus:\n",
    "    tokenized_corpus.append(tokenizer2.tokenize(i['text']))\n",
    "\n",
    "stemmed_corpus=[]\n",
    "for i in tokenized_corpus:\n",
    "    temp=[]\n",
    "    for y in i:\n",
    "        u=stemmer.stem(y)\n",
    "        temp.append(u)\n",
    "    stemmed_corpus.append(temp)\n",
    "for i in(stemmed_corpus[0][1:10]):\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_corpus=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ког 2\n",
      "код 2\n",
      "журна 1\n",
      "присутств 1\n",
      "модел 1\n",
      "тольк 3\n",
      "« 1\n",
      "межд 1\n",
      "и 29\n",
      "картинок 1\n",
      "под 1\n",
      "поступа 1\n",
      "коллег 1\n",
      "прогоня 1\n",
      "пот 1\n",
      "переверста 1\n",
      "подправ 1\n",
      "визуальн 1\n",
      "команд 1\n",
      "разработчик 1\n",
      "-> 3\n",
      "выкидыва 1\n",
      "определ 1\n",
      "име 1\n",
      "результат 1\n",
      "пачк 1\n",
      "связност 1\n",
      "над 1\n",
      "ориентирова 1\n",
      "след 1\n",
      "цикл 3\n",
      "дизайн 5\n",
      "средств 1\n",
      "подход 1\n",
      "следова 1\n",
      "так 4\n",
      "там 1\n",
      "внест 1\n",
      "эт 9\n",
      "решен 2\n",
      "топор 1\n",
      "упроща 1\n",
      "что 9\n",
      "планир 1\n",
      "для 8\n",
      "тут 2\n",
      "обновля 1\n",
      "описа 1\n",
      "равн 1\n",
      "конц 1\n",
      "где 4\n",
      "заказчик 1\n",
      "дела 5\n",
      "о 1\n",
      "времен 3\n",
      "момент 2\n",
      "”, 1\n",
      "всегд 2\n",
      "вещ 1\n",
      "типов 1\n",
      "крошек 1\n",
      "многолетн 1\n",
      "верстк 6\n",
      "проектирован 2\n",
      "JavaScript 1\n",
      "дизайнер 1\n",
      "работ 4\n",
      "ест 4\n",
      "на 14\n",
      "изменен 4\n",
      "помощ 1\n",
      "систем 1\n",
      "трех 1\n",
      "по 8\n",
      "конкретн 1\n",
      "набор 3\n",
      "показа 1\n",
      "поня 2\n",
      "мног 3\n",
      "отмеч 1\n",
      "контекст 1\n",
      "писа 1\n",
      "имен 1\n",
      "заменител 1\n",
      "устаревш 1\n",
      "пользовательск 1\n",
      "намн 1\n",
      "один 1\n",
      "хот 2\n",
      "“ 3\n",
      "инстанц 1\n",
      "ве 2\n",
      "спорн 1\n",
      "RP 1\n",
      "во 1\n",
      "валидн 1\n",
      ", 49\n",
      "вероятн 1\n",
      "URL 1\n",
      "банальн 1\n",
      "про 2\n",
      "при 2\n",
      "хорош 2\n",
      "наход 1\n",
      "контент 1\n",
      "тех 2\n",
      "ipsum 1\n",
      "ход 2\n",
      "вмест 1\n",
      "Pro 1\n",
      "активн 1\n",
      "отража 1\n",
      "вест 1\n",
      "показыва 1\n",
      "categor 2\n",
      "ил 4\n",
      "ним 1\n",
      "проектировщик 4\n",
      "из 3\n",
      "ид 1\n",
      "рук 1\n",
      "сверста 1\n",
      "ссылк 1\n",
      "приписа 1\n",
      "два 1\n",
      "я 4\n",
      "сраз 1\n",
      "раз 3\n",
      "контрол 1\n",
      "далек 1\n",
      "конечн 1\n",
      "них 1\n",
      "catalog 3\n",
      "их 5\n",
      "реша 1\n",
      "рискова 1\n",
      "когд 1\n",
      "проработк 1\n",
      "создан 5\n",
      "теря 1\n",
      "сут 2\n",
      "он 4\n",
      "быт 3\n",
      "част 7\n",
      "пользовател 1\n",
      "бы 1\n",
      "взаимодейств 2\n",
      "трат 1\n",
      "lor 1\n",
      "обраща 1\n",
      "оценок 1\n",
      "ведут 1\n",
      "линковк 1\n",
      "стара 4\n",
      "нужн 8\n",
      "есл 6\n",
      "головач 1\n",
      "закончат 1\n",
      "сценар 1\n",
      "долг 1\n",
      "к 6\n",
      "долж 3\n",
      "тормоз 1\n",
      "знач 2\n",
      "включа 1\n",
      "задач 1\n",
      "вручн 1\n",
      "продума 1\n",
      "прода 1\n",
      "перв 2\n",
      "чтоб 2\n",
      "начист 1\n",
      "правк 1\n",
      "использован 3\n",
      "” 1\n",
      "пакет 1\n",
      "варк 1\n",
      "три 1\n",
      "- 22\n",
      "е 1\n",
      "обещан 1\n",
      "тестирован 6\n",
      "обрат 2\n",
      "бол 2\n",
      "макет 3\n",
      "промежуточн 2\n",
      "восприят 1\n",
      "хват 2\n",
      "проект 4\n",
      "интерактивн 6\n",
      "юзабилит 5\n",
      "чита 1\n",
      "оригина 1\n",
      "расписа 2\n",
      "элемент 2\n",
      "( 2\n",
      "а 5\n",
      "процесс 8\n",
      "вот 1\n",
      "”. 1\n",
      "верс 3\n",
      "не 12\n",
      "соб 1\n",
      "но 3\n",
      "чег 1\n",
      "слишк 1\n",
      "поможет 1\n",
      "получа 1\n",
      "вход 1\n",
      "провер 1\n",
      "новост 1\n",
      "большинств 1\n",
      "важн 4\n",
      "поменя 1\n",
      "шапк 1\n",
      "себ 2\n",
      "всех 2\n",
      "одн 1\n",
      "обсужден 3\n",
      "будет 3\n",
      "3 1\n",
      "начина 1\n",
      "принцип 1\n",
      "тел 1\n",
      "прост 4\n",
      "дополн 1\n",
      "качествен 1\n",
      "разниц 1\n",
      "сер 1\n",
      "смотр 1\n",
      "всег 1\n",
      "главн 2\n",
      "прич 1\n",
      "пут 1\n",
      "лучш 12\n",
      "лишн 1\n",
      "неч 1\n",
      "нет 1\n",
      "сложност 1\n",
      "поддержк 1\n",
      "Intuitect 1\n",
      "же 2\n",
      "особен 2\n",
      "правд 1\n",
      "хлебн 1\n",
      "футер 1\n",
      ". 64\n",
      "итог 1\n",
      "уж 3\n",
      "характер 1\n",
      "достойн 1\n",
      "помога 2\n",
      "тогд 1\n",
      "связыван 1\n",
      "тон 1\n",
      "том 1\n",
      "тог 1\n",
      "». 1\n",
      "целостн 1\n",
      "случа 1\n",
      "источник 1\n",
      "оставля 1\n",
      "точк 1\n",
      "точн 1\n",
      "нем 1\n",
      "поэт 1\n",
      "it 1\n",
      "менеджер 1\n",
      "качеств 2\n",
      "файл 4\n",
      "горазд 2\n",
      "эталон 1\n",
      "достаточн 1\n",
      "занима 2\n",
      "увлека 1\n",
      "html 3\n",
      "отдельн 2\n",
      "явля 1\n",
      "добавля 1\n",
      "с 5\n",
      "HTML 6\n",
      "люб 1\n",
      "обычн 3\n",
      "поддержива 1\n",
      "связа 1\n",
      "врем 2\n",
      "меня 1\n",
      "сам 5\n",
      "начал 2\n",
      "окончан 2\n",
      "игрушк 1\n",
      "мы 2\n",
      "практик 1\n",
      "сло 1\n",
      "пособ 1\n",
      "понятн 1\n",
      "ещ 3\n",
      "— 16\n",
      "заточ 1\n",
      "wireframes 3\n",
      "эксперимент 2\n",
      "преимуществ 1\n",
      "даж 2\n",
      "гот 1\n",
      "актуальн 1\n",
      "дан 1\n",
      "вариант 1\n",
      "экспертн 1\n",
      "удобн 1\n",
      "шаблон 3\n",
      "удобств 1\n",
      "альтернативн 1\n",
      "схем 3\n",
      "арм 1\n",
      "чист 1\n",
      "здоров 1\n",
      "кристальн 1\n",
      "назван 3\n",
      "использова 2\n",
      "ег 2\n",
      "описан 1\n",
      "те 1\n",
      "альтернатив 1\n",
      "то 5\n",
      "потрат 2\n",
      "придет 1\n",
      "), 2\n",
      "нескольк 2\n",
      "плюс 1\n",
      "осяза 1\n",
      "знаком 1\n",
      "партнер 1\n",
      "отличн 1\n",
      "польз 1\n",
      "правильн 1\n",
      "нача 1\n",
      "участник 1\n",
      "цветн 1\n",
      "знает 1\n",
      "перечен 1\n",
      "особ 1\n",
      "например 2\n",
      "реализова 1\n",
      "пар 2\n",
      "фиксир 1\n",
      "посл 4\n",
      "расскажет 1\n",
      "все 5\n",
      "кажд 1\n",
      "основ 2\n",
      "материа 1\n",
      "зат 1\n",
      "верстальщик 3\n",
      "забыва 1\n",
      "бумаг 1\n",
      "тестов 1\n",
      "постоя 2\n",
      "приход 1\n",
      "нестандартн 1\n",
      "наброск 1\n",
      "в 17\n",
      "действующ 1\n",
      "Axur 1\n",
      ": 2\n",
      "подготов 1\n",
      "очен 1\n",
      "можн 1\n",
      "увлеч 1\n",
      "списк 1\n",
      "воспринима 1\n",
      "прощ 3\n",
      "последн 3\n",
      "интерфейс 7\n",
      "красот 1\n",
      "этап 2\n",
      "инвестор 1\n",
      "страниц 11\n",
      "документац 4\n",
      "втор 1\n",
      "перед 1\n",
      "каш 1\n",
      "влад 1\n",
      "классификац 2\n",
      "стат 2\n",
      "до 1\n",
      "разработк 1\n",
      "выход 1\n",
      "устарел 1\n",
      "да 3\n",
      "уйм 1\n",
      "нибуд 1\n",
      "автоматическ 1\n",
      "прототип 22\n",
      "минимум 1\n",
      "работа 1\n",
      "быстр 1\n",
      "основн 1\n",
      "дороговат 2\n",
      "как 8\n",
      "готов 1\n",
      "программ 1\n",
      "котор 3\n",
      "расписыва 1\n",
      "провод 1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "bags_for_corpus=[]\n",
    "for i in stemmed_corpus:\n",
    "    cur_dict={}\n",
    "    for y in i:\n",
    "        if y in cur_dict: cur_dict[y]+=1\n",
    "        else: cur_dict[y]=1\n",
    "    bags_for_corpus.append(cur_dict)\n",
    "\n",
    "for i in bags_for_corpus[0]:\n",
    "    sys.stdout.write(i)\n",
    "    print (' '+str(bags_for_corpus[0][i]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 232\n",
      "облак 37\n",
      "EXPLAIN 1\n",
      "облад 5\n",
      "синусойдн 1\n",
      "функционирован 8\n",
      "делауэр 1\n",
      "переоценива 2\n",
      "Int32 1\n",
      "3YXXNTsuntusVzhkupON 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "token_doc_cnt = Counter()\n",
    "for bow in bags_for_corpus:\n",
    "    token_doc_cnt += Counter(bow.keys())\n",
    "                    \n",
    "lim=0              \n",
    "for i in token_doc_cnt:\n",
    "    sys.stdout.write (i)\n",
    "    sys.stdout.write (' ')\n",
    "    print token_doc_cnt[i]\n",
    "    lim+=1\n",
    "    if lim>9: break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counters=Counter()\n",
    "for i in bags_for_corpus:\n",
    "    for y in i:\n",
    "        for z in bags_for_corpus:\n",
    "            if y in z: \n",
    "                counters[y]+=1\n",
    "                \n",
    "# lim=0              \n",
    "# for i in counters:\n",
    "#     if counters[i]>len(bags_for_corpus):\n",
    "#         sys.stdout.write (i)\n",
    "#         sys.stdout.write (' ')\n",
    "#         print counters[i]\n",
    "#         lim+=1\n",
    "#         if lim>9: break\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "# idf={}\n",
    "for i in counters:\n",
    "    idf[i] = math.log(len(bags_for_corpus)*1.0/counters[i])\n",
    "lim=0      \n",
    "\n",
    "# print(' ')\n",
    "# print(' ')\n",
    "# for i in idf:\n",
    "#     if idf[i]<0:\n",
    "#         sys.stdout.write (i)\n",
    "#         sys.stdout.write (' ')\n",
    "#         print idf[i]\n",
    "#         lim+=1\n",
    "#         if lim>9: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "counters=token_doc_cnt\n",
    "idf={}\n",
    "for i in counters:\n",
    "    idf[i] = math.log(len(bags_for_corpus)*1.0/counters[i])\n",
    "lim=0      \n",
    "\n",
    "# print(' ')\n",
    "# print(' ')\n",
    "# for i in idf:\n",
    "#     if idf[i]<0.5:\n",
    "#         sys.stdout.write (i)\n",
    "#         sys.stdout.write (' ')\n",
    "#         print idf[i]\n",
    "#         lim+=1\n",
    "#         if lim>100: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf-idf для каждого документа\n",
    "tfidfs=[]\n",
    "for i in bags_for_corpus:\n",
    "    temp={}\n",
    "    for y in i:\n",
    "        temp[y]=i[y]*idf[y]\n",
    "    tfidfs.append(temp)\n",
    "print (tfidfs[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Насколько похожи документы 4 и 7\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
