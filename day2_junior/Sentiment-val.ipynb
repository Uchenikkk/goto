{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "tweets = pandas.DataFrame.from_csv(\"Tweets data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Sentiment                                      SentimentText\n",
      "ItemID                                                              \n",
      "1               0                       is so sad for my APL frie...\n",
      "5002            1       very very very happy and slightly skinny  xx\n",
      "10012           1  &quot;I feel better now, better than James Bro...\n",
      "15012           1  ...what can I say ....what a surprise...http:/...\n",
      "20012           0                                     @ ponyp: hey! \n",
      "25012           1       @404world yes I'm going to find one..pronto \n",
      "30012           0  @AdamJonesey mmm id love some parma violets ri...\n",
      "35012           1  @AlTheYid Roast beef and wasabi... yummmmmmmmm...\n",
      "40012           0  @amandafortier ahhh. yeah. kinda. I tweet from...\n",
      "45012           0                 @antdeshawn ... the pain is worst \n",
      "50012           1  @Ashtarte Just be your usual supportive self. ...\n",
      "55012           0  @azizabatini86 and that's fine--u kno, the dry...\n",
      "60012           0       @Bellemorda I miss you!!! Get back on soon. \n",
      "65012           0  @BrandyWandLover yer so was i hun. sum guy was...\n",
      "70012           0  @Andreicaaat Aww damn I can watch your vid on ...\n",
      "75012           1                      @anorangegal You've got mail \n",
      "80012           1  @cantyka hallo juga  thanks ya udah di follow....\n",
      "85012           0  @cbhamby easy there tiger...you should have co...\n",
      "90012           1  @clickjow depois tu pode ver outras s�ries. te...\n",
      "95012           0  @cianw I've never really been able to eat muss...\n"
     ]
    }
   ],
   "source": [
    "print(tweets[::5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing\n",
    "Извлечём из твитов признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = tweets[\"SentimentText\"]\n",
    "Y = tweets[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = []\n",
    "    \n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    #<для начала будем использовать частоты букв как признаки>\n",
    "    letters = \"abcdefghijklmnopqrstuvwxyz\"    \n",
    "    for l in letters:\n",
    "        features.append(text.count(l))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "X = []\n",
    "for text in texts:\n",
    "    X.append(extract_features(text))\n",
    "X = numpy.array(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a model\n",
    "Научим на наших признаках простую линейную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#порежем данные\n",
    "X_train = X[:70000]\n",
    "Y_train = Y[:70000]\n",
    "X_test = X[70000:]\n",
    "Y_test = Y[70000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03976119, -0.02395792,  0.03336063, -0.07673787,  0.01470141,\n",
       "         0.04481567,  0.04607898,  0.00136932, -0.04444427,  0.14625134,\n",
       "         0.05731417,  0.04799672, -0.05269558, -0.03541793,  0.01029763,\n",
       "         0.01853502,  0.23346672,  0.02136664, -0.06216603, -0.03674036,\n",
       "         0.03427765,  0.02921815, -0.01795578,  0.06048928,  0.04883713,\n",
       "         0.06188793]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred_train = <предскажите вероятности для обучающей выборки>\n",
    "Y_pred_test = <предскажите вероятности для обучающей выборки>\n",
    "print(\"Обучение:\",roc_auc_score(Y_train,Y_pred_train))\n",
    "print(\"Тест:\",roc_auc_score(Y_test,Y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opinion mining\n",
    "\n",
    "Давайте использовуем нашу модель чтобы понять, что людям сейчас нравится/не нравится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "with open(\"testdata.txt\") as fin:\n",
    "    test_tweets = fin.read()[:-1].split('\\n')\n",
    "test_tweets = numpy.array(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\" I don\\'t care what anyone says, I like Hillary Clinton.'\n",
      " 'have an awesome time at purdue!..'\n",
      " \"Yep, I'm still in London, which is pretty awesome: P Remind me to post the million and one pictures that I took when I get back to Markham!...\"\n",
      " \"Have to say, I hate Paris Hilton's behavior but I do think she's kinda cute..\"\n",
      " 'i will love the lakers.']\n"
     ]
    }
   ],
   "source": [
    "print test_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ops = []\n",
    "for tweet in test_tweets:\n",
    "    X_ops.append(extract_features(tweet))\n",
    "X_ops = numpy.array(X_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiments = model.predict_proba(X_ops)[:,1]\n",
    "sentiment_order = numpy.argsort(-sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### теперь посмотрим на наиболее любимые/ненавистные людям вещи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999999999999 : OMFG HONDA SUCKS @ @ @ @ @ @ @ @ @ @ @ @ @ FORD A < > L < > L < > THE WAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY.\n",
      "0.901456613199 : i love sa manthaaaaa aaa aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa aaaaaaaaaaaaaaaa.. < nononeofyouknowherandit'snottheoneyourthinkingabout >..\n",
      "0.881983628014 : gnun ata talaga pag nageenejoy ka at ngeenjoy ka sa mga kasama mo. you guys make every difficult things in school easy, kc alam ko nandyan kyo to back everyone up.\n",
      "0.861247808836 : I love Angelina Jolie, Heath Ledger, Jake Gyllenhall, Arnold Vosloo, Faruza Balk, Jason Wiles, Molly Price, Julia Roberts, Chris Meloni, Mariska Hargitay, Brendan Fraiser, Mel Gibson, Julian McMahon, Dennis Leary, Phillip Seymour Hoffman, Sean Patrick Thomas and more...\n",
      "0.83106839537 : apparently Harvard College is the undergraduate program of Harvard University, i thought Harvard College was some crappy college playing off of the real thing..\n",
      "0.814906872354 : AAA ya se empezare dandoles la grata noticia q se me fue la caspa q tenia detras de la cabeza aquel horrible dia.\n",
      "0.797526909828 : u baggin on my boy jake cuz if u is i could straight fuck you azz up lil bitch holla ata playa..\n",
      "0.78166119408 : I really like the Davis Square, Porter Square, and Harvard Square areas.\n",
      "0.777229698926 : anyway then the concert was AMAZING-harvard collegiate is really really really good, they have a gorgeous sound.\n",
      "0.771996026743 : wow all i know is that cory looks jokey in that picture well anyways yah i loved hangin out ata cheddars we should all do that again well anyways holla at yah boy lata skeedah(\n"
     ]
    }
   ],
   "source": [
    "best_ids = sentiment_order[:10]\n",
    "\n",
    "for tweet, score in zip(test_tweets[best_ids], sentiments[best_ids]):\n",
    "    print score,':',tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.253944425179 : I thought I could be more than just his friend, that the whole friends w / benefits thing wouldn't bother me, but I decided when I was in San Francisco that that is such a horrible idea.\n",
      "0.253944425179 : I thought I could be more than just his friend, that the whole friends w / benefits thing wouldn't bother me, but I decided when I was in San Francisco that that is such a horrible idea.\n",
      "0.244636665 : I have two weddings and a birthday party to work at and attend this weekend, and the State Farm inspector is coming on Monday to determine the fate of my beloved Thunderbird.\n",
      "0.243953203614 : substantiated debt consolidation loans gm mastercard customizing debt elimination He's simply too inept otherwise..\n",
      "0.231546696305 : the first time, i got to spend time with sansan and tito robbie in the san francisco museum of modern art ( which was awesome, btw.\n",
      "0.22702564168 : I spent a good bit of time racing around the city on my bike, and last night I went to see Mission Impossible 3 since Tom Cruise is awesome.\n",
      "0.216634291582 : i remember i hated shanghai last year i didnt want to move i wanted to die nd i cried everyday nd hated everyone hated SAS and i didnt want to go there or be in shanghai.\n",
      "0.214818585694 : Most of this is related to the fact that what I'm doing here in London is good, but it isn't convincing me it's what I should be doing with my life.\n",
      "0.195160884872 : I wanted to test drive both the Stang and the Scion, but when we hit the Toyota lot I spotted the stalker man from my previous visit and busted an immediate bitch.\n",
      "0.186104706966 : apart from the shopsssssssssssssss n shops and endless shops on the streets, looking pretty exciting but Shanghai is soooo sucking boring to me now!!!!!!!!!!!..\n"
     ]
    }
   ],
   "source": [
    "worst_ids = sentiment_order[-10:]\n",
    "\n",
    "for tweet, score in zip(test_tweets[worst_ids], sentiments[worst_ids]):\n",
    "    print score,':',tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_words = [w for ws in text for w in ws.lower().split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(text_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-7b02ce1ec87d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mword_to_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "words = list(set(words))\n",
    "word_to_id = {word:i for i,word in enumerate(list(words))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#выделите 1000 cлов, которые имеют наиболее разную вероятность войти в позитивный и негативный твит\n",
    "bag_of_words = <слова-признаки>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = []\n",
    "    \n",
    "    words = filter(len,text.lower().split())\n",
    "    \n",
    "    <bag of words для слов>\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "X = []\n",
    "for text in texts:\n",
    "    X.append(extract_features(text))\n",
    "X = numpy.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = <обучите модель>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_train = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "Y_pred_test = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "print(\"Обучение:\",roc_auc_score(Y_train,Y_pred_train))\n",
    "print(\"Тест:\",roc_auc_score(Y_test,Y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collocations\n",
    "Найдём наиболее частые коллокации и используем их как признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cfinder = collocations.BigramCollocationFinder.from_words(text_words)\n",
    "cfinder.apply_freq_filter(5)\n",
    "measure = collocations.BigramAssocMeasures.raw_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(cfinder.nbest(measure,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    features = []\n",
    "    \n",
    "    <bag of words для коллокаций>\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "X = []\n",
    "for text in texts:\n",
    "    X.append(extract_features(text))\n",
    "X = numpy.array(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = <обучите модель>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_train = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "Y_pred_test = <предскажите вероятности для обучающей выборки copy-paste>\n",
    "print(\"Обучение:\",roc_auc_score(Y_train,Y_pred_train))\n",
    "print(\"Тест:\",roc_auc_score(Y_test,Y_pred_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
